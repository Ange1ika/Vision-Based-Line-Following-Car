# Vision-Based Line-Following Car ğŸš—âš¡

Real-time autonomous Raspberry Pi car using **YOLOv8 Segmentation (TFLite / OpenVINO)** and classical **OpenCV** vision.
Supports smooth steering, angle detection for 90Â° turns, telemetry logging, and modular detector backend.

---

## ğŸŒŸ Key Features

### ğŸ” **1. YOLO-Based Segmentation**

Supports two segmentation backends:

* **OpenVINO (recommended):** 2.5Ã— faster than TFLite
* **TFLite:** portable, works without dependencies

### ğŸ¥ **2. Line Detection & ROI System**

* Upper / lower ROI split
* Centroid detection
* ROI bins (left/center/right)
* Pixel mass weighted center

### ğŸ§­ **3. Angle Detection**

* Detects 90Â° turns
* Detects sharp turns
* Uses region-based heuristics + temporal smoothing

### âš™ï¸ **4. Steering Controller**

* PID-like correction
* Speed modulation near turns
* Smooth maneuvering state machine

### ğŸ“Š **5. Telemetry & Debugging**

* CSV logs of speeds, states, ROI values
* Optional overlay with line mask, centers, ROI grid
* Debug display mode

---

# ğŸ—‚ Project Structure

```bash
Vision-Based-Line-Following-Car/
â”œâ”€â”€ checkpoints/                    # YOLO models (TFLite, ONNX, OpenVINO)
â”œâ”€â”€ data/
â”œâ”€â”€ demo/                           
â”‚   â”œâ”€â”€ openvino_result.jpg
â”‚   â”œâ”€â”€ tflite_result.jpg
â”‚   â”œâ”€â”€ driving_demo.gif
â”‚   â””â”€â”€ mask_overlay_example.png
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ YoloLineDetector.py         # YOLOv8-seg â†’ mask â†’ binary output
â”‚   â”œâ”€â”€ line_detector.py            # Classical OpenCV detector
â”‚   â”œâ”€â”€ angle_analyzer.py
â”‚   â”œâ”€â”€ controller.py               # Vision + steering main logic
â”‚   â”œâ”€â”€ motor_controller.py
â”‚   â”œâ”€â”€ camera_module.py
â”‚   â”œâ”€â”€ main.py                     # Full system runtime
â”‚   â””â”€â”€ convertation/               # Model export tools
â”‚       â”œâ”€â”€ check_openvino.py
â”‚       â”œâ”€â”€ tf_check.py
â”‚       â”œâ”€â”€ yoloPth2Tflite.py
â”‚       â””â”€â”€ openvino_convertation.py
â”‚
â””â”€â”€ README.md
```

---

# âš¡ Segmentation Backends: OpenVINO vs TFLite

We support two YOLOv8-seg model formats:

| Backend            | Time per frame | FPS          | Notes                              |
| ------------------ | -------------- | ------------ | ---------------------------------- |
| **TFLite Float16** | **124.17 ms**  | **8.1 FPS**  | Slow postprocess, good portability |
| **OpenVINO FP16**  | **46.14 ms**   | **21.7 FPS** | âš¡ FASTEST, recommended             |

To convert pth to tflite, find a guide here: src/convertation/steps.md
One script is used to convert openvino: src/convertation/openvino_convertation.py

### âœ” Why OpenVINO is faster?

* Optimized linear algebra
* Batch-friendly GEMM kernels
* Fast sigmoid/mask reconstruction
* Multithreading even on CPU
* Efficient FP16 support

**Conclusion: use OpenVINO for real robot driving**

---

# ğŸ“¸ Demo Results (demo/)


```
demo/
â”œâ”€â”€ openvino_result.jpg       # mask overlay from OpenVINO
â”œâ”€â”€ tflite_result.jpg         # mask overlay from TFLite
â”œâ”€â”€ driving_demo.gif          # optional driving animation
â””â”€â”€ mask_overlay_example.png
```

---

### ğŸ–¼ OpenVINO Output Example

<img src="demo/openvino_result.jpg" width="500"/>

### ğŸ–¼ TFLite Output Example

<img src="demo/tflite_result.jpg" width="500"/>

---

# â–¶ï¸ Run the System

### Use YOLOv8 Segmentation (default)

```bash
python3 src/main.py
```
Change the opencv mode in the src/controller.py

